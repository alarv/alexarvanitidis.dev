export const metadata = {
  title: "Coding with Claude code and LLMs: What I've learned after 3 months",
  description:
    'Reflections on working daily with Claude Code and LLMs for three months, the benefits of full repo context, and why experience still matters.',
}

export const revalidate = 3600 * 24

# Coding with Claude code and LLMs: What I've learned after 3 months

<PublishedOn date={new Date(2025, 5, 26)} />

<Cover
  src="/coding-with-claude-code-and-llms.png"
  alt="Coding-with-claude-code-and-llms"
/>

For the past three months, I've worked daily with Claude Code and most major LLMs.
If you've used them, you know one thing: they don't have the full context of your codebase.
This means you often need to feed them long, detailed prompts just to get the basics done.

Claude Code is different. It can see your entire repo, which changes everything.
I've found that 90% of the time, it gets the job done with minimal help.
The other 10%? It confidently gives you the wrong answer. But you can usually guide it back on track if you know what you're doing.

That's where experience kicks in. I started coding back in 2012.
Looking back, if I had today's AI tools then, I'd have shipped a lot more features.
But I would've missed something important: training my brain to spot bugs, edge cases, and bad logic just by reading the code.
That kind of intuition only comes with time and effort.

Now, I mostly use LLMs as assistants. I catch what they miss.
I guide them, correct them.
But here's my one worry: if we rely too much on these tools, our minds will dull.
We'll lose that sharpness that comes from struggling through hard problems.

Can LLMs replace developers?
**Not in this lifetime**, not with the way they work today.
As Yann LeCun explained in [this talk](https://www.youtube.com/watch?v=4__gg83s_Do), scaling LLMs isn't enough to reach general intelligence.
We're not close to real understanding.

So yes, use the tools. But don't stop thinking.
